{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac012635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict , Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import cross_entropy\n",
    "from datasets import Dataset , DatasetDict , Sequence , Value , Features , ClassLabel\n",
    "from transformers import AutoTokenizer , XLMRobertaConfig , AutoConfig , TrainingArguments , DataCollatorForTokenClassification , Trainer\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "from seqeval.metrics import f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay , confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datasets import load_from_disk\n",
    "import warnings\n",
    "from transformers import AutoTokenizer\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "data = load_from_disk(\"PEYMA_ARMAN_MIXED.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655f629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at E:\\ML\\NLP_Toolbox\\NER\\PEYMA_ARMAN_MIXED.hf\\train\\cache-57424060d946b530.arrow\n",
      "Loading cached shuffled indices for dataset at E:\\ML\\NLP_Toolbox\\NER\\PEYMA_ARMAN_MIXED.hf\\test\\cache-adcc49eea328fe12.arrow\n",
      "Loading cached shuffled indices for dataset at E:\\ML\\NLP_Toolbox\\NER\\PEYMA_ARMAN_MIXED.hf\\validation\\cache-430e59aedb1cb7f5.arrow\n"
     ]
    }
   ],
   "source": [
    "data = data.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7976c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_model_name = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84607ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParsXMLRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    \n",
    "    class_config = XLMRobertaConfig\n",
    "    \n",
    "    def __init__(self , config):\n",
    "        \n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.num_labels = config.num_labels\n",
    "        \n",
    "        self.roberta = RobertaModel(config , add_pooling_layer=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        \n",
    "        self.classifier = nn.Linear(config.hidden_size , config.num_labels)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self , input_ids=None , attention_mask=None , token_type_ids=None , labels=None , **kwargs):\n",
    "\n",
    "        outputs = self.roberta(input_ids , attention_mask=attention_mask , token_type_ids=token_type_ids , **kwargs)\n",
    "\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1 , self.num_labels) , labels.view(-1))\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss = loss,\n",
    "            logits = logits,\n",
    "            hidden_states = outputs.hidden_states,\n",
    "            attentions = outputs.attentions\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c9ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags = data['train']['ner_tags_names']\n",
    "ner_tag_names = set(tag for tags in ner_tags for tag in tags)\n",
    "                \n",
    "index2tag = {idx: tag for idx, tag in enumerate(ner_tag_names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(ner_tag_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc61a6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁رهبر</td>\n",
       "      <td>▁کو</td>\n",
       "      <td>با</td>\n",
       "      <td>▁در</td>\n",
       "      <td>▁خاتم</td>\n",
       "      <td>ه</td>\n",
       "      <td>▁گفت</td>\n",
       "      <td>▁:</td>\n",
       "      <td>▁هرچند</td>\n",
       "      <td>▁</td>\n",
       "      <td>رؤ</td>\n",
       "      <td>ی</td>\n",
       "      <td>ای</td>\n",
       "      <td>▁داشتن</td>\n",
       "      <td>▁قوانین</td>\n",
       "      <td>▁عادل</td>\n",
       "      <td>انه</td>\n",
       "      <td>▁به</td>\n",
       "      <td>▁نظر</td>\n",
       "      <td>▁بسیاری</td>\n",
       "      <td>▁نام</td>\n",
       "      <td>م</td>\n",
       "      <td>کن</td>\n",
       "      <td>▁می</td>\n",
       "      <td>▁رسد</td>\n",
       "      <td>▁ولی</td>\n",
       "      <td>▁به</td>\n",
       "      <td>▁اعتقاد</td>\n",
       "      <td>▁ما</td>\n",
       "      <td>▁مبارزه</td>\n",
       "      <td>▁برای</td>\n",
       "      <td>▁نام</td>\n",
       "      <td>م</td>\n",
       "      <td>کن</td>\n",
       "      <td>▁باید</td>\n",
       "      <td>▁شعار</td>\n",
       "      <td>▁این</td>\n",
       "      <td>▁نهاد</td>\n",
       "      <td>▁بین</td>\n",
       "      <td>▁المللی</td>\n",
       "      <td>▁باشد</td>\n",
       "      <td>▁كه</td>\n",
       "      <td>▁امروز</td>\n",
       "      <td>▁ما</td>\n",
       "      <td>▁را</td>\n",
       "      <td>▁گرد</td>\n",
       "      <td>▁هم</td>\n",
       "      <td>▁آورده</td>\n",
       "      <td>▁است</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>50773</td>\n",
       "      <td>554</td>\n",
       "      <td>6779</td>\n",
       "      <td>175</td>\n",
       "      <td>118483</td>\n",
       "      <td>176</td>\n",
       "      <td>5228</td>\n",
       "      <td>152</td>\n",
       "      <td>180173</td>\n",
       "      <td>6</td>\n",
       "      <td>47044</td>\n",
       "      <td>140</td>\n",
       "      <td>6223</td>\n",
       "      <td>47613</td>\n",
       "      <td>32642</td>\n",
       "      <td>106257</td>\n",
       "      <td>7189</td>\n",
       "      <td>178</td>\n",
       "      <td>2580</td>\n",
       "      <td>30778</td>\n",
       "      <td>2618</td>\n",
       "      <td>376</td>\n",
       "      <td>15329</td>\n",
       "      <td>383</td>\n",
       "      <td>54606</td>\n",
       "      <td>11174</td>\n",
       "      <td>178</td>\n",
       "      <td>114251</td>\n",
       "      <td>877</td>\n",
       "      <td>56636</td>\n",
       "      <td>1012</td>\n",
       "      <td>2618</td>\n",
       "      <td>376</td>\n",
       "      <td>15329</td>\n",
       "      <td>3969</td>\n",
       "      <td>75543</td>\n",
       "      <td>498</td>\n",
       "      <td>73830</td>\n",
       "      <td>5184</td>\n",
       "      <td>35033</td>\n",
       "      <td>3105</td>\n",
       "      <td>6695</td>\n",
       "      <td>15199</td>\n",
       "      <td>877</td>\n",
       "      <td>406</td>\n",
       "      <td>28849</td>\n",
       "      <td>1149</td>\n",
       "      <td>109008</td>\n",
       "      <td>477</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1    2     3    4       5    6     7    8       9  10  \\\n",
       "Tokens     <s>  ▁رهبر  ▁کو    با  ▁در   ▁خاتم    ه  ▁گفت   ▁:  ▁هرچند  ▁   \n",
       "Input IDs    0  50773  554  6779  175  118483  176  5228  152  180173  6   \n",
       "\n",
       "              11   12    13      14       15      16    17   18    19  \\\n",
       "Tokens        رؤ    ی    ای  ▁داشتن  ▁قوانین   ▁عادل   انه  ▁به  ▁نظر   \n",
       "Input IDs  47044  140  6223   47613    32642  106257  7189  178  2580   \n",
       "\n",
       "                20    21   22     23   24     25     26   27       28   29  \\\n",
       "Tokens     ▁بسیاری  ▁نام    م     کن  ▁می   ▁رسد   ▁ولی  ▁به  ▁اعتقاد  ▁ما   \n",
       "Input IDs    30778  2618  376  15329  383  54606  11174  178   114251  877   \n",
       "\n",
       "                30     31    32   33     34     35     36    37     38    39  \\\n",
       "Tokens     ▁مبارزه  ▁برای  ▁نام    م     کن  ▁باید  ▁شعار  ▁این  ▁نهاد  ▁بین   \n",
       "Input IDs    56636   1012  2618  376  15329   3969  75543   498  73830  5184   \n",
       "\n",
       "                40     41    42      43   44   45     46    47      48    49  \\\n",
       "Tokens     ▁المللی  ▁باشد   ▁كه  ▁امروز  ▁ما  ▁را   ▁گرد   ▁هم  ▁آورده  ▁است   \n",
       "Input IDs    35033   3105  6695   15199  877  406  28849  1149  109008   477   \n",
       "\n",
       "          50 51    52  \n",
       "Tokens     ▁  .  </s>  \n",
       "Input IDs  6  5     2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "per_text = \" \".join(data['train']['tokens'][0])\n",
    "input_ids = tokenizer.encode(per_text, return_tensors=\"pt\")\n",
    "roberta_tokens = tokenizer(per_text).tokens()\n",
    "pd.DataFrame([roberta_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13fe513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_model_name, add_prefix_space=True)\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = roberta_tokenizer(examples[\"tokens\"], truncation=True,\n",
    "    is_split_into_words=True)\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags_names\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_token = label[word_idx]\n",
    "                # Use the label map to get the numerical value for each entity\n",
    "                label_ids.append(tag2index[label_token])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "642b77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels,batched=True,\n",
    "                      remove_columns=['tokens' , 'ner_tags' , 'ner_tags_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "172f22f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3303 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_data = encode_panx_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf1f338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "roberta_config  = AutoConfig.from_pretrained(\n",
    "    roberta_model_name,\n",
    "    num_labels = len(index2tag),\n",
    "    id2label = index2tag,\n",
    "    label2id = tag2index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab4d2ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 26417\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3303\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3302\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d4f695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "        preds = np.argmax(predictions, axis=2)\n",
    "        batch_size, seq_len = preds.shape\n",
    "        labels_list, preds_list = [], []\n",
    "        for batch_idx in range(batch_size):\n",
    "            example_labels, example_preds = [], []\n",
    "            for seq_idx in range(seq_len):\n",
    "                # Ignore label IDs = -100\n",
    "                if label_ids[batch_idx, seq_idx] != -100:\n",
    "                    example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                    example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "            labels_list.append(example_labels)\n",
    "            preds_list.append(example_preds)\n",
    "        return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4b33bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "import torch\n",
    "\n",
    "num_epochs = 6\n",
    "batch_size = 24\n",
    "logging_steps = len(encoded_data['train']) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output\", log_level=\"error\", num_train_epochs=num_epochs,\n",
    "    gradient_checkpointing=True,\n",
    "#     fp16=True,\n",
    "\n",
    "    eval_accumulation_steps=10,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    seed=42,\n",
    "    logging_strategy=\"steps\", evaluation_strategy=\"epoch\",\n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n",
    "    logging_steps=logging_steps, push_to_hub=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00aef084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (ParsXMLRobertaForTokenClassification\n",
    "                  .from_pretrained(roberta_model_name, config=roberta_config,cache_dir=Path.cwd())\n",
    "                  .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72532ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "# Use the custom data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84b42146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score,recall_score,precision_score,accuracy_score\n",
    "import wandb\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions,\n",
    "    eval_pred.label_ids)\n",
    "    wandb.log({\"f1\": f1_score(y_true, y_pred),\"Recall\":recall_score(y_true, y_pred),\"Precision\":precision_score(y_true, y_pred),\"Accuracy\":accuracy_score(y_true, y_pred)})\n",
    "    return {\"f1\": f1_score(y_true, y_pred),\"Recall\":recall_score(y_true, y_pred),\"Precision\":precision_score(y_true, y_pred),\"Accuracy\":accuracy_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acdd94a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                    train_dataset=encoded_data['train'],\n",
    "                    eval_dataset=encoded_data['validation'],\n",
    "                    tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca5b350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mali-fartout\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc52dbea9614ec2ad9eac6a5ac3210b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>E:\\ML\\NLP_Toolbox\\NER\\wandb\\run-20230816_160934-mvvgd2r5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ali-fartout/XMLRoberta_number1/runs/mvvgd2r5' target=\"_blank\">upbeat-dew-2</a></strong> to <a href='https://wandb.ai/ali-fartout/XMLRoberta_number1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ali-fartout/XMLRoberta_number1' target=\"_blank\">https://wandb.ai/ali-fartout/XMLRoberta_number1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ali-fartout/XMLRoberta_number1/runs/mvvgd2r5' target=\"_blank\">https://wandb.ai/ali-fartout/XMLRoberta_number1/runs/mvvgd2r5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6606' max='6606' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6606/6606 22:45, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.075124</td>\n",
       "      <td>0.805203</td>\n",
       "      <td>0.841218</td>\n",
       "      <td>0.772146</td>\n",
       "      <td>0.974965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.049409</td>\n",
       "      <td>0.868926</td>\n",
       "      <td>0.884397</td>\n",
       "      <td>0.853987</td>\n",
       "      <td>0.985016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.038347</td>\n",
       "      <td>0.908677</td>\n",
       "      <td>0.926028</td>\n",
       "      <td>0.891964</td>\n",
       "      <td>0.989570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.036428</td>\n",
       "      <td>0.927879</td>\n",
       "      <td>0.938414</td>\n",
       "      <td>0.917578</td>\n",
       "      <td>0.991048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.035513</td>\n",
       "      <td>0.937579</td>\n",
       "      <td>0.952176</td>\n",
       "      <td>0.923423</td>\n",
       "      <td>0.992074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.037769</td>\n",
       "      <td>0.939868</td>\n",
       "      <td>0.951832</td>\n",
       "      <td>0.928200</td>\n",
       "      <td>0.992277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▅▇███</td></tr><tr><td>Precision</td><td>▁▅▆███</td></tr><tr><td>Recall</td><td>▁▄▆▇██</td></tr><tr><td>eval/Accuracy</td><td>▁▅▇███</td></tr><tr><td>eval/Precision</td><td>▁▅▆███</td></tr><tr><td>eval/Recall</td><td>▁▄▆▇██</td></tr><tr><td>eval/f1</td><td>▁▄▆▇██</td></tr><tr><td>eval/loss</td><td>█▃▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▃▂█▃▂</td></tr><tr><td>eval/samples_per_second</td><td>█▆▇▁▅▆</td></tr><tr><td>eval/steps_per_second</td><td>█▆▇▁▅▆</td></tr><tr><td>f1</td><td>▁▄▆▇██</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▄▄▅▅▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▄▄▄▅▅▅▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.99228</td></tr><tr><td>Precision</td><td>0.9282</td></tr><tr><td>Recall</td><td>0.95183</td></tr><tr><td>eval/Accuracy</td><td>0.99228</td></tr><tr><td>eval/Precision</td><td>0.9282</td></tr><tr><td>eval/Recall</td><td>0.95183</td></tr><tr><td>eval/f1</td><td>0.93987</td></tr><tr><td>eval/loss</td><td>0.03777</td></tr><tr><td>eval/runtime</td><td>7.7726</td></tr><tr><td>eval/samples_per_second</td><td>424.825</td></tr><tr><td>eval/steps_per_second</td><td>17.755</td></tr><tr><td>f1</td><td>0.93987</td></tr><tr><td>train/epoch</td><td>6.0</td></tr><tr><td>train/global_step</td><td>6606</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0048</td></tr><tr><td>train/total_flos</td><td>8829263516821506.0</td></tr><tr><td>train/train_loss</td><td>0.04154</td></tr><tr><td>train/train_runtime</td><td>1366.6884</td></tr><tr><td>train/train_samples_per_second</td><td>115.975</td></tr><tr><td>train/train_steps_per_second</td><td>4.834</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-dew-2</strong> at: <a href='https://wandb.ai/ali-fartout/XMLRoberta_number1/runs/mvvgd2r5' target=\"_blank\">https://wandb.ai/ali-fartout/XMLRoberta_number1/runs/mvvgd2r5</a><br/> View job at <a href='https://wandb.ai/ali-fartout/XMLRoberta_number1/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjkwODU4Mjcz/version_details/v1' target=\"_blank\">https://wandb.ai/ali-fartout/XMLRoberta_number1/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjkwODU4Mjcz/version_details/v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230816_160934-mvvgd2r5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"XMLRoberta_number1\")\n",
    "result = trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78aa5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text,tags,tokenizer):\n",
    "    \n",
    "    \"\"\"\n",
    "    Output a DataFrame showing tokens with their predicted label\n",
    "    \n",
    "        text : [string] User inputed text\n",
    "        model : Model object\n",
    "        tags : [ClassLabel] Tags\n",
    "        tokenizer : Model tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = tokenizer(text).tokens()\n",
    "    \n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    outputs = trainer.model(input_ids)[0]\n",
    "    predictions = torch.argmax(outputs, dim=2)    \n",
    "    preds = [tags[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens , preds] , index=['token' , 'predicted label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abbe7e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁ناس</td>\n",
       "      <td>ا</td>\n",
       "      <td>▁در</td>\n",
       "      <td>▁تاریخ</td>\n",
       "      <td>▁28</td>\n",
       "      <td>▁شهریور</td>\n",
       "      <td>▁با</td>\n",
       "      <td>▁کمک</td>\n",
       "      <td>▁شرکت</td>\n",
       "      <td>▁اسپ</td>\n",
       "      <td>یس</td>\n",
       "      <td>▁ایکس</td>\n",
       "      <td>▁به</td>\n",
       "      <td>▁مالک</td>\n",
       "      <td>یت</td>\n",
       "      <td>▁ایل</td>\n",
       "      <td>ان</td>\n",
       "      <td>▁ما</td>\n",
       "      <td>سک</td>\n",
       "      <td>،</td>\n",
       "      <td>▁فضا</td>\n",
       "      <td>نورد</td>\n",
       "      <td>ان</td>\n",
       "      <td>▁خود</td>\n",
       "      <td>▁را</td>\n",
       "      <td>▁از</td>\n",
       "      <td>▁ایالت</td>\n",
       "      <td>▁می</td>\n",
       "      <td>نه</td>\n",
       "      <td>▁سو</td>\n",
       "      <td>تا</td>\n",
       "      <td>▁به</td>\n",
       "      <td>▁سمت</td>\n",
       "      <td>▁ایستگاه</td>\n",
       "      <td>▁فضایی</td>\n",
       "      <td>▁بین</td>\n",
       "      <td>▁المللی</td>\n",
       "      <td>▁فرستاد</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted label</th>\n",
       "      <td>O</td>\n",
       "      <td>B_ORG</td>\n",
       "      <td>I_ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B_DAT</td>\n",
       "      <td>I_DAT</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B_ORG</td>\n",
       "      <td>I_ORG</td>\n",
       "      <td>I_ORG</td>\n",
       "      <td>I_ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B_PER</td>\n",
       "      <td>I_PER</td>\n",
       "      <td>I_PER</td>\n",
       "      <td>I_PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B_LOC</td>\n",
       "      <td>I_LOC</td>\n",
       "      <td>I_LOC</td>\n",
       "      <td>I_LOC</td>\n",
       "      <td>I_LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B_LOC</td>\n",
       "      <td>I_LOC</td>\n",
       "      <td>I_LOC</td>\n",
       "      <td>I_LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0      1      2    3       4      5        6    7     8   \\\n",
       "token            <s>   ▁ناس      ا  ▁در  ▁تاریخ    ▁28  ▁شهریور  ▁با  ▁کمک   \n",
       "predicted label    O  B_ORG  I_ORG    O       O  B_DAT    I_DAT    O     O   \n",
       "\n",
       "                    9      10     11     12   13     14  15     16     17  \\\n",
       "token            ▁شرکت   ▁اسپ     یس  ▁ایکس  ▁به  ▁مالک  یت   ▁ایل     ان   \n",
       "predicted label  B_ORG  I_ORG  I_ORG  I_ORG    O      O   O  B_PER  I_PER   \n",
       "\n",
       "                    18     19 20    21    22  23    24   25   26      27  \\\n",
       "token              ▁ما     سک  ،  ▁فضا  نورد  ان  ▁خود  ▁را  ▁از  ▁ایالت   \n",
       "predicted label  I_PER  I_PER  O     O     O   O     O    O    O   B_LOC   \n",
       "\n",
       "                    28     29     30     31   32    33        34      35  \\\n",
       "token              ▁می     نه    ▁سو     تا  ▁به  ▁سمت  ▁ایستگاه  ▁فضایی   \n",
       "predicted label  I_LOC  I_LOC  I_LOC  I_LOC    O     O     B_LOC   I_LOC   \n",
       "\n",
       "                    36       37       38 39    40  \n",
       "token             ▁بین  ▁المللی  ▁فرستاد  .  </s>  \n",
       "predicted label  I_LOC    I_LOC        O  O     O  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'ناسا در تاریخ 28 شهریور با کمک شرکت اسپیس ایکس به مالکیت ایلان ماسک، فضانوردان خود را از ایالت مینه سوتا به سمت ایستگاه فضایی بین المللی فرستاد.'\n",
    "tag_text(text , list(ner_tag_names) , tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "913c9e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁در</td>\n",
       "      <td>▁بیماری</td>\n",
       "      <td>▁</td>\n",
       "      <td>لائم</td>\n",
       "      <td>▁،</td>\n",
       "      <td>▁درد</td>\n",
       "      <td>های</td>\n",
       "      <td>▁بند</td>\n",
       "      <td>ها</td>\n",
       "      <td>▁ناشی</td>\n",
       "      <td>▁از</td>\n",
       "      <td>▁عفونت</td>\n",
       "      <td>▁می</td>\n",
       "      <td>کر</td>\n",
       "      <td>بی</td>\n",
       "      <td>▁است</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted label</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0    1        2  3     4   5     6    7     8   9      10  \\\n",
       "token            <s>  ▁در  ▁بیماری  ▁  لائم  ▁،  ▁درد  های  ▁بند  ها  ▁ناشی   \n",
       "predicted label    O    O        O  O     O   O     O    O     O   O      O   \n",
       "\n",
       "                  11      12   13  14  15    16 17    18  \n",
       "token            ▁از  ▁عفونت  ▁می  کر  بی  ▁است  .  </s>  \n",
       "predicted label    O       O    O   O   O     O  O     O  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(data['test']['tokens'][3][:-1]) + data['test']['tokens'][3][-1]\n",
    "tag_text(text , list(ner_tag_names) , tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d30b4f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['test']['ner_tags_names'][3]),len(data['test']['tokens'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2387c43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁در</td>\n",
       "      <td>▁بیماری</td>\n",
       "      <td>▁</td>\n",
       "      <td>لائم</td>\n",
       "      <td>▁،</td>\n",
       "      <td>▁درد</td>\n",
       "      <td>های</td>\n",
       "      <td>▁بند</td>\n",
       "      <td>ها</td>\n",
       "      <td>▁ناشی</td>\n",
       "      <td>▁از</td>\n",
       "      <td>▁عفونت</td>\n",
       "      <td>▁می</td>\n",
       "      <td>کر</td>\n",
       "      <td>بی</td>\n",
       "      <td>▁است</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted label</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0    1        2  3     4   5     6    7     8   9      10  \\\n",
       "token            <s>  ▁در  ▁بیماری  ▁  لائم  ▁،  ▁درد  های  ▁بند  ها  ▁ناشی   \n",
       "predicted label    O    O        O  O     O   O     O    O     O   O      O   \n",
       "\n",
       "                  11      12   13  14  15    16 17    18  \n",
       "token            ▁از  ▁عفونت  ▁می  کر  بی  ▁است  .  </s>  \n",
       "predicted label    O       O    O   O   O     O  O     O  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_text(text , list(ner_tag_names) , tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pytorch]",
   "language": "python",
   "name": "conda-env-Pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
