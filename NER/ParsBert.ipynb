{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca98b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "data = load_from_disk(\"PEYMA_ARMAN_MIXED.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc83052",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a7f592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'ner_tags_names'],\n",
       "        num_rows: 26417\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'ner_tags_names'],\n",
       "        num_rows: 3303\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'ner_tags_names'],\n",
       "        num_rows: 3302\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27cc7712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jack', 'Sp', '##ar', '##row', 'love', '##s', 'New', 'York', '!']\n",
      "['سلام', 'خوب', 'هستید', '؟']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from pathlib import Path\n",
    "parsbert_model_name = \"HooshvareLab/bert-fa-zwnj-base\"\n",
    "parsbert_tokenizer = AutoTokenizer.from_pretrained(parsbert_model_name,cache_dir=Path.cwd())\n",
    "\n",
    "text = \"Jack Sparrow loves New York!\"\n",
    "print(parsbert_tokenizer.tokenize(text))\n",
    "\n",
    "text = \"سلام خوب هستید؟\"\n",
    "print(parsbert_tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2547da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at HooshvareLab/bert-fa-zwnj-base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "from pathlib import Path\n",
    "parsbert_model = AutoModel.from_pretrained(parsbert_model_name,cache_dir=Path.cwd())\n",
    "parsbert_config = AutoConfig.from_pretrained(parsbert_model_name,cache_dir=Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea3d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel,BertModel \n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CustomBertModel(BertModel):\n",
    "    def __init__(self, config):\n",
    "        super(CustomBertModel, self).__init__(config)\n",
    "        # Remove the pooler part\n",
    "        self.pooler = None\n",
    "\n",
    "# Load the pre-trained BERT model\n",
    "model_name = \"HooshvareLab/bert-fa-zwnj-base\"  # Replace with the appropriate model name\n",
    "config = AutoConfig.from_pretrained(model_name,cache_dir=Path.cwd())\n",
    "\n",
    "\n",
    "class ParsBertForTokenClassification(BertPreTrainedModel):\n",
    "    config_class = config\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Load model body\n",
    "        self.parsbert = CustomBertModel(config)\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # Load and initialize weights\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        \n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.parsbert(input_ids, attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids, **kwargs)\n",
    "        \n",
    "        # Apply classifier to encoder representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        \n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            \n",
    "        # Return model output object\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits,\n",
    "        hidden_states=outputs.hidden_states,\n",
    "        attentions=outputs.attentions)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd4cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags = data[\"train\"][\"ner_tags_names\"]\n",
    "ner_tag_names = set(tag for tags in ner_tags for tag in tags)\n",
    "                \n",
    "index2tag = {idx: tag for idx, tag in enumerate(ner_tag_names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(ner_tag_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49f5a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "parsbert_config = AutoConfig.from_pretrained(parsbert_model_name,num_labels=len(index2tag),\n",
    "                                            id2label=index2tag, label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86e386aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>رهبر</td>\n",
       "      <td>کوبا</td>\n",
       "      <td>در</td>\n",
       "      <td>خاتمه</td>\n",
       "      <td>گفت</td>\n",
       "      <td>:</td>\n",
       "      <td>هرچند</td>\n",
       "      <td>[UNK]</td>\n",
       "      <td>داشتن</td>\n",
       "      <td>قوانین</td>\n",
       "      <td>عادلانه</td>\n",
       "      <td>به</td>\n",
       "      <td>نظر</td>\n",
       "      <td>بسیاری</td>\n",
       "      <td>ناممکن</td>\n",
       "      <td>می</td>\n",
       "      <td>[ZWNJ]</td>\n",
       "      <td>رسد</td>\n",
       "      <td>ولی</td>\n",
       "      <td>به</td>\n",
       "      <td>اعتقاد</td>\n",
       "      <td>ما</td>\n",
       "      <td>مبارزه</td>\n",
       "      <td>برای</td>\n",
       "      <td>ناممکن</td>\n",
       "      <td>باید</td>\n",
       "      <td>شعار</td>\n",
       "      <td>این</td>\n",
       "      <td>نهاد</td>\n",
       "      <td>بین</td>\n",
       "      <td>[ZWNJ]</td>\n",
       "      <td>المللی</td>\n",
       "      <td>باشد</td>\n",
       "      <td>[UNK]</td>\n",
       "      <td>امروز</td>\n",
       "      <td>ما</td>\n",
       "      <td>را</td>\n",
       "      <td>گرد</td>\n",
       "      <td>هم</td>\n",
       "      <td>آ</td>\n",
       "      <td>##ورده</td>\n",
       "      <td>است</td>\n",
       "      <td>.</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>2</td>\n",
       "      <td>4055</td>\n",
       "      <td>10867</td>\n",
       "      <td>1921</td>\n",
       "      <td>10127</td>\n",
       "      <td>2228</td>\n",
       "      <td>133</td>\n",
       "      <td>4459</td>\n",
       "      <td>1</td>\n",
       "      <td>3328</td>\n",
       "      <td>4227</td>\n",
       "      <td>12847</td>\n",
       "      <td>1923</td>\n",
       "      <td>2161</td>\n",
       "      <td>2489</td>\n",
       "      <td>18590</td>\n",
       "      <td>1924</td>\n",
       "      <td>9</td>\n",
       "      <td>2784</td>\n",
       "      <td>2515</td>\n",
       "      <td>1923</td>\n",
       "      <td>5567</td>\n",
       "      <td>2121</td>\n",
       "      <td>4779</td>\n",
       "      <td>1959</td>\n",
       "      <td>18590</td>\n",
       "      <td>2129</td>\n",
       "      <td>7614</td>\n",
       "      <td>1930</td>\n",
       "      <td>5501</td>\n",
       "      <td>2136</td>\n",
       "      <td>9</td>\n",
       "      <td>3166</td>\n",
       "      <td>2094</td>\n",
       "      <td>1</td>\n",
       "      <td>2902</td>\n",
       "      <td>2121</td>\n",
       "      <td>1937</td>\n",
       "      <td>2309</td>\n",
       "      <td>1951</td>\n",
       "      <td>595</td>\n",
       "      <td>4832</td>\n",
       "      <td>1933</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     1      2     3      4     5    6      7      8      9   \\\n",
       "Tokens     [CLS]  رهبر   کوبا    در  خاتمه   گفت    :  هرچند  [UNK]  داشتن   \n",
       "Input IDs      2  4055  10867  1921  10127  2228  133   4459      1   3328   \n",
       "\n",
       "               10       11    12    13      14      15    16      17    18  \\\n",
       "Tokens     قوانین  عادلانه    به   نظر  بسیاری  ناممکن    می  [ZWNJ]   رسد   \n",
       "Input IDs    4227    12847  1923  2161    2489   18590  1924       9  2784   \n",
       "\n",
       "             19    20      21    22      23    24      25    26    27    28  \\\n",
       "Tokens      ولی    به  اعتقاد    ما  مبارزه  برای  ناممکن  باید  شعار   این   \n",
       "Input IDs  2515  1923    5567  2121    4779  1959   18590  2129  7614  1930   \n",
       "\n",
       "             29    30      31      32    33     34     35    36    37    38  \\\n",
       "Tokens     نهاد   بین  [ZWNJ]  المللی  باشد  [UNK]  امروز    ما    را   گرد   \n",
       "Input IDs  5501  2136       9    3166  2094      1   2902  2121  1937  2309   \n",
       "\n",
       "             39   40      41    42   43     44  \n",
       "Tokens       هم    آ  ##ورده   است    .  [SEP]  \n",
       "Input IDs  1951  595    4832  1933  121      3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "per_text = \" \".join(data[\"train\"]['tokens'][0])\n",
    "input_ids = parsbert_tokenizer.encode(per_text, return_tensors=\"pt\")\n",
    "bert_tokens = parsbert_tokenizer(per_text).tokens()\n",
    "pd.DataFrame([bert_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2ed4613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 921f1a10-d5d5-48f7-a802-7d69e65d8fbb)')' thrown while requesting HEAD https://huggingface.co/HooshvareLab/bert-fa-zwnj-base/resolve/main/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "parsbert_tokenizer = AutoTokenizer.from_pretrained(parsbert_model_name,\n",
    "                                                   use_fast = True,\n",
    "                                                   add_prefix_space=True)\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = parsbert_tokenizer(examples[\"tokens\"], truncation=True,\n",
    "    is_split_into_words=True)\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags_names\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e766c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels,batched=True,\n",
    "                      remove_columns=['ner_tags',\"ner_tags_names\",'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5975f0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3303 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_data = encode_panx_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10c8ee28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 26417\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3303\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3302\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff8ee7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d015409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (ParsBertForTokenClassification\n",
    "                  .from_pretrained(parsbert_model_name, config=parsbert_config,cache_dir=Path.cwd())\n",
    "                  .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8957fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "import torch\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 24\n",
    "\n",
    "logging_steps = len(data[\"train\"]) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output\", log_level=\"error\", num_train_epochs=num_epochs,\n",
    "    gradient_checkpointing=True,\n",
    "#     fp16=True,\n",
    "    eval_accumulation_steps=10,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    seed=42,\n",
    "    logging_strategy=\"steps\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_steps=1e6,\n",
    "    weight_decay=0.01,\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps, push_to_hub=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dbc909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "# Use the custom data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=parsbert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bde6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score,recall_score,precision_score,accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions,\n",
    "    eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred),\"Recall\":recall_score(y_true, y_pred),\"Precision\":precision_score(y_true, y_pred),\"Accuracy\":accuracy_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86926f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3303' max='3303' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3303/3303 09:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.327700</td>\n",
       "      <td>0.223917</td>\n",
       "      <td>0.391096</td>\n",
       "      <td>0.463960</td>\n",
       "      <td>0.338012</td>\n",
       "      <td>0.931491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>0.148905</td>\n",
       "      <td>0.558523</td>\n",
       "      <td>0.629623</td>\n",
       "      <td>0.501851</td>\n",
       "      <td>0.952535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.122653</td>\n",
       "      <td>0.626144</td>\n",
       "      <td>0.694650</td>\n",
       "      <td>0.569936</td>\n",
       "      <td>0.961441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_ORG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_ORG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_DAT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_DAT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_FAC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_FAC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_TIM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_TIM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_MON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_MON seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_PRO seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_EVE seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_EVE seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_PCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_PCT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\11\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_PRO seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3303, training_loss=0.20393840521077766, metrics={'train_runtime': 572.0385, 'train_samples_per_second': 138.541, 'train_steps_per_second': 5.774, 'total_flos': 4077424220431086.0, 'train_loss': 0.20393840521077766, 'epoch': 3.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# print(training_args)\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                        data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                        train_dataset=encoded_data[\"train\"],\n",
    "                        eval_dataset=encoded_data[\"validation\"],\n",
    "                        tokenizer=parsbert_tokenizer)\n",
    "trainer.train()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2ae0551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>ناسا</td>\n",
       "      <td>در</td>\n",
       "      <td>تاریخ</td>\n",
       "      <td>28</td>\n",
       "      <td>شهریور</td>\n",
       "      <td>با</td>\n",
       "      <td>کمک</td>\n",
       "      <td>شرکت</td>\n",
       "      <td>اسپیس</td>\n",
       "      <td>ایکس</td>\n",
       "      <td>به</td>\n",
       "      <td>مالکیت</td>\n",
       "      <td>ایلان</td>\n",
       "      <td>ماسک</td>\n",
       "      <td>،</td>\n",
       "      <td>فضانوردان</td>\n",
       "      <td>خود</td>\n",
       "      <td>را</td>\n",
       "      <td>از</td>\n",
       "      <td>ایالت</td>\n",
       "      <td>مینه</td>\n",
       "      <td>سوتا</td>\n",
       "      <td>به</td>\n",
       "      <td>سمت</td>\n",
       "      <td>ایستگاه</td>\n",
       "      <td>فضایی</td>\n",
       "      <td>بین</td>\n",
       "      <td>المللی</td>\n",
       "      <td>فرستاد</td>\n",
       "      <td>.</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B_PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>I_DAT</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B_ORG</td>\n",
       "      <td>I_ORG</td>\n",
       "      <td>I_ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>I_ORG</td>\n",
       "      <td>I_ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B_LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1   2      3   4       5   6    7      8      9      10  11  \\\n",
       "Tokens  [CLS]   ناسا  در  تاریخ  28  شهریور  با  کمک   شرکت  اسپیس   ایکس  به   \n",
       "Tags        O  B_PER   O      O   O   I_DAT   O    O  B_ORG  I_ORG  I_ORG   O   \n",
       "\n",
       "            12     13     14 15         16   17  18  19     20    21    22  \\\n",
       "Tokens  مالکیت  ایلان   ماسک  ،  فضانوردان  خود  را  از  ایالت  مینه  سوتا   \n",
       "Tags         O  I_ORG  I_ORG  O          O    O   O   O  B_LOC     O     O   \n",
       "\n",
       "        23   24       25     26   27      28      29 30     31  \n",
       "Tokens  به  سمت  ایستگاه  فضایی  بین  المللی  فرستاد  .  [SEP]  \n",
       "Tags     O    O        O      O    O       O       O  O      O  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'ناسا در تاریخ 28 شهریور با کمک شرکت اسپیس ایکس به مالکیت ایلان ماسک، فضانوردان خود را از ایالت مینه سوتا به سمت ایستگاه فضایی بین المللی فرستاد.'\n",
    "tokens = parsbert_tokenizer(example).tokens()\n",
    "input_ids = parsbert_tokenizer(example, return_tensors=\"pt\").input_ids.to(device)\n",
    "outputs = trainer.model(input_ids)[0]\n",
    "# Take argmax to get most likely class per token\n",
    "predictions = torch.argmax(outputs, dim=2)\n",
    "# Convert to DataFrame\n",
    "tags = list(ner_tag_names)\n",
    "preds = [tags[p] for p in predictions[0].cpu().numpy()]\n",
    "pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826924b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pytorch]",
   "language": "python",
   "name": "conda-env-Pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
