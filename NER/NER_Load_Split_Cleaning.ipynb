{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28cc82b",
   "metadata": {},
   "source": [
    "# Download and Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1dc6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25cf68b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = Path(r\"E:\\ML\\NLP_Toolbox\\NER\\polyglot_ner\\combined\\1.0.0\\bb2e45c90cd345c87dfd757c8e2b808b78b0094543b511ac49bc0129699609c1\")\n",
    "data = []\n",
    "for file_path in folder_path.glob(\"*\"):\n",
    "    if file_path.is_file():\n",
    "        data.append(str(file_path.resolve()))\n",
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7d3c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset arrow (C:/Users/11/.cache/huggingface/datasets/arrow/default-5bc4303e6b42c700/0.0.0/74f69db2c14c2860059d39860b1f400a03d11bf7fb5a8258ca38c501c878c137)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = load_dataset(\"arrow\", data_files=data,split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884487a",
   "metadata": {},
   "source": [
    "# testing Persian and English corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eaa3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d437873b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\11\\.cache\\huggingface\\datasets\\arrow\\default-5bc4303e6b42c700\\0.0.0\\74f69db2c14c2860059d39860b1f400a03d11bf7fb5a8258ca38c501c878c137\\cache-e7769ddc44ade02a.arrow\n"
     ]
    }
   ],
   "source": [
    "# Define the filter condition\n",
    "filter_condition = lambda example: example[\"lang\"] == \"fa\" or example[\"lang\"] == \"en\"\n",
    "\n",
    "# Apply the filter\n",
    "corpus = dataset.filter(filter_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5caff54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c733e30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>words</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>831560</th>\n",
       "      <td>16203661</td>\n",
       "      <td>en</td>\n",
       "      <td>[These, 2, guns, were, non-standard, and, fire...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469097</th>\n",
       "      <td>11384991</td>\n",
       "      <td>fa</td>\n",
       "      <td>[نیمه, غایب, کتابی, از, حسین, سناپور, است, .]</td>\n",
       "      <td>[O, O, O, O, PER, PER, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37378</th>\n",
       "      <td>10953272</td>\n",
       "      <td>fa</td>\n",
       "      <td>[آنها, شامل, بالاخانوادهٔ, میمون, بر, قدیم, و,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700678</th>\n",
       "      <td>16072779</td>\n",
       "      <td>en</td>\n",
       "      <td>[In, 1992, ,, New, York, City, Mayor, David, D...</td>\n",
       "      <td>[O, O, O, O, O, O, O, PER, PER, O, PER, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169097</th>\n",
       "      <td>11084991</td>\n",
       "      <td>fa</td>\n",
       "      <td>[فلت, راک, شهری, در, ایالت, کارولینای, شمالی, ...</td>\n",
       "      <td>[LOC, O, O, O, LOC, LOC, LOC, O, LOC, LOC, LOC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id lang                                              words  \\\n",
       "831560  16203661   en  [These, 2, guns, were, non-standard, and, fire...   \n",
       "469097  11384991   fa      [نیمه, غایب, کتابی, از, حسین, سناپور, است, .]   \n",
       "37378   10953272   fa  [آنها, شامل, بالاخانوادهٔ, میمون, بر, قدیم, و,...   \n",
       "700678  16072779   en  [In, 1992, ,, New, York, City, Mayor, David, D...   \n",
       "169097  11084991   fa  [فلت, راک, شهری, در, ایالت, کارولینای, شمالی, ...   \n",
       "\n",
       "                                                      ner  \n",
       "831560  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "469097                       [O, O, O, O, PER, PER, O, O]  \n",
       "37378                   [O, O, O, O, O, O, O, O, O, O, O]  \n",
       "700678  [O, O, O, O, O, O, O, PER, PER, O, PER, O, O, ...  \n",
       "169097  [LOC, O, O, O, LOC, LOC, LOC, O, LOC, LOC, LOC...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5841d8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 916885 entries, 0 to 916884\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      916885 non-null  object\n",
      " 1   lang    916885 non-null  object\n",
      " 2   words   916885 non-null  object\n",
      " 3   ner     916885 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 28.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7b6503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fa    492903\n",
       "en    423982\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "005e659b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'e', 'f', 'n'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tags = set()\n",
    "\n",
    "for tags in df['lang']:\n",
    "    unique_tags.update(tags)\n",
    "\n",
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abc8765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per = df.loc[df['lang']==\"fa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d5aa487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df.loc[df['lang']==\"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f4a951e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "در قرن سوم پیش از میلاد هندسه توسط اقلیدس به شکل اصل موضوعی در آمده بود و کار اقلیدس - هندسه اقلیدسی - استانداردی را پایه ریزی نمود که قرنها دنبال شد .\n",
      "O,O,O,O,O,O,O,O,PER,O,O,O,O,O,O,O,O,O,PER,O,O,O,O,O,O,O,O,O,O,O,O,O,O\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "rnd = randint(0,len(df_per))\n",
    "print(\" \".join(df_per.iloc[rnd][\"words\"]))\n",
    "print(\",\".join(df_per.iloc[rnd][\"ner\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2da2d522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He then moved to France , where he spent one season with Stade Français before joining FC Sochaux in 1929 , where he would remain until 1938 .\n",
      "O,O,O,O,O,O,O,O,O,O,O,O,ORG,ORG,O,O,ORG,ORG,O,O,O,O,O,O,O,O,O,O\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "rnd = randint(0,len(df_en))\n",
    "print(\" \".join(df_en.iloc[rnd][\"words\"]))\n",
    "print(\",\".join(df_en.iloc[rnd][\"ner\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9ce6a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>529168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>347971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>314055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "LOC  529168\n",
       "PER  347971\n",
       "ORG  314055"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = {}\n",
    "for row in df[\"ner\"]:\n",
    "     for tag in row:\n",
    "        if tag != \"O\":\n",
    "            if tag not in counter.keys():\n",
    "                 counter[tag] = 1\n",
    "            else:\n",
    "                 counter[tag]  = counter[tag]  + 1\n",
    "                \n",
    "    \n",
    "pd.DataFrame.from_dict(counter, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebb737e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['۳', ')', 'انتشاردر', 'این', 'مکانیزم', 'نتیجه', 'عملکرد', 'فیلتر', 'بطرز', 'چشمگیری', 'افزایش', 'می', 'یابد', '.', 'در', 'اثر', 'تصادم', 'مولکول', 'های', 'گازی', 'با', 'ذرات', 'معلق', 'بسیار', 'کوچک', '(', 'کمتر', 'از', '۰', '/', '۱', 'میکرون', ')', 'جهت', 'حرکت', 'ذرات', 'معلق', 'در', 'داخل', 'فیلتر', 'تغییر', 'کرده', 'و', 'سرعت', 'اش', 'نیز', 'کاهش', 'می', 'یابد', 'و', 'همین', 'تأخیر', 'باعث', 'بالا', 'رفتن', 'احتمال', 'توقف', 'و', 'گیرکردن', 'ذره', 'معلق', 'در', 'درون', 'فیلتر', 'می', 'شود', '.(', 'قابل', 'مقایسه', 'باپدیده', 'فیزیکی', '\"', 'حرکت', 'بروانین', '\")', 'این', 'روش', 'در', 'جذب', 'ذرات', 'با', 'قطر', 'کمتر', 'از', '۰', '/', '۱', 'میکرون', 'روش', 'برتر', 'می', 'باشد.همانطور', 'که', 'دو', 'روش', 'تراکم', 'و', 'مسدود', 'کردن', 'در', 'جذب', 'ذرات', 'بالاتر', 'از', '۰', '/', '۴', 'میکرون', 'مؤثر', 'می', 'باشند.ذرات', 'بین', 'این', 'دو', 'اندازه', 'بیشترین', 'نفوذ', 'را', 'در', 'فیلتر', 'می', 'کنند', '(', '۰', '/', '۳', 'میکرون', ')', 'که', 'توأماً', 'توسط', 'هر', 'سه', 'عامل', 'به', 'کمک', 'هم', 'در', 'فیلتر', 'گیر', 'می', 'افتند', '.']\n"
     ]
    }
   ],
   "source": [
    "for row in df[\"words\"]:\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8005d1d5",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "50dd83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\11\\.cache\\huggingface\\datasets\\arrow\\default-5bc4303e6b42c700\\0.0.0\\74f69db2c14c2860059d39860b1f400a03d11bf7fb5a8258ca38c501c878c137\\cache-822c5d6a012fbc65.arrow\n",
      "Loading cached processed dataset at C:\\Users\\11\\.cache\\huggingface\\datasets\\arrow\\default-5bc4303e6b42c700\\0.0.0\\74f69db2c14c2860059d39860b1f400a03d11bf7fb5a8258ca38c501c878c137\\cache-e5244abdbe194ace.arrow\n"
     ]
    }
   ],
   "source": [
    "filter_persian_condition = lambda example: example[\"lang\"] == \"fa\"\n",
    "filter_english_condition  = lambda example: example[\"lang\"] == \"en\"\n",
    "\n",
    "persian = dataset.filter(filter_persian_condition)\n",
    "english = dataset.filter(filter_english_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "570b0a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "916885"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(persian) + len(english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0002059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "persian_spllited = persian.train_test_split(test_size=0.2)\n",
    "english_spllited = english.train_test_split(test_size=0.2)\n",
    "\n",
    "train = datasets.concatenate_datasets([persian_spllited['train'], english_spllited['train']])\n",
    "test = datasets.concatenate_datasets([persian_spllited['test'], english_spllited['test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "14e3def2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'lang', 'words', 'ner'],\n",
       "    num_rows: 733507\n",
       "})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b186365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'lang', 'words', 'ner'],\n",
       "    num_rows: 183378\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dee2894a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "916885"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test) + len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa15198c",
   "metadata": {},
   "source": [
    "# Check and save dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb4e0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "41e4efee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While Ann contemplates switching to the cosmetics business , LeTour , who suffers from insomnia , has lost his perspective in life .\n",
      "O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "rnd = randint(0,len(df))\n",
    "print(\" \".join(df.iloc[rnd][\"words\"]))\n",
    "print(\",\".join(df.iloc[rnd][\"ner\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9c66c889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/733507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/183378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.save_to_disk(\"train.hf\")\n",
    "test.save_to_disk(\"test.hf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Pytorch]",
   "language": "python",
   "name": "conda-env-Pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
